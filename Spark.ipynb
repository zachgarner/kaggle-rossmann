{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import DataFrame\n",
    "import numpy\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from pandas import Series\n",
    "import datetime\n",
    "import pandas\n",
    "from pandas import DataFrame, Series\n",
    "import numpy\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import preprocessing\n",
    "#%matplotlib inline # Only works on Python 3 in the docker container\n",
    "#import seaborn # Only works on Python 3 in the docker container\n",
    "\n",
    "#import os\n",
    "#os.environ['PYSPARK_PYTHON'] = 'python2'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'cal:dayOfMonth', 'cal:dayOfWeek', 'cal:dayofyear', 'cal:month', 'cal:quarter', 'cal:weekofyear', 'cal:year']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf = DataFrame.from_csv(\"train_all_featurized.csv\", index_col=None)\n",
    "pdf.head()\n",
    "\n",
    "columns = list(pdf.columns)\n",
    "print (columns)\n",
    "columns.remove(\"Sales\")\n",
    "columns = [\"Sales\"] + columns\n",
    "\n",
    "pdf = pdf[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+--------------------+\n",
      "|        prediction|  label|            features|\n",
      "+------------------+-------+--------------------+\n",
      "| 5874.547455119309| 5263.0|[1.0,5.0,555.0,1....|\n",
      "| 6618.831553903145| 6064.0|[2.0,5.0,625.0,1....|\n",
      "| 8718.658209732106| 8314.0|[3.0,5.0,821.0,1....|\n",
      "|12074.145054040415|13995.0|[4.0,5.0,1498.0,1...|\n",
      "|10268.303219099058|10457.0|[11.0,5.0,1236.0,...|\n",
      "+------------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24845299384131375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import cross_validation\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.createDataFrame(pdf)\n",
    "df = df.map(lambda row: LabeledPoint(row[0], row[1:])).toDF()\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=2000).fit(df)\n",
    "# 0.28756570690198635 with maxCat=4\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(numTrees=20, maxDepth=7, maxBins=1200, featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "# print \"Root Mean Squared Error (RMSE) on test data = %g\" % rmse\n",
    "\n",
    "# Compute RMPSE\n",
    "squares = predictions.rdd.filter(lambda x: x.label != 0).map(lambda x: ((x.label - x.prediction) / x.label) *  ((x.label - x.prediction) / x.label))\n",
    "\n",
    "mean = squares.mean()\n",
    "import math\n",
    "math.sqrt(mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
